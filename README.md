
---

#üî∞ Simulation de la difusion de chaleur avec les  R√©seaux de Neuronesinform√© par la physique (Pinns).

Ce projet est mon projet tutor√© lor de ma troisi√®me ann√©e en G√©nie Math√©matique et Mod√©lisation √† l'ENSGMM.
Ic on impl√©mente un r√©seau de neurones profond inform√© par la physique  pour r√©soudre une √©quation diff√©rentielle partielle (PDE) de la diffussion de chaleur  √† l'aide de la m√©thode des r√©seaux de neurones bas√©s sur la physique (Physics-Informed Neural Networks - PINNs). Nous utilisons PyTorch pour l'entra√Ænement et la r√©solution  et inclut les m√©thodes d'optimisation  Adam et L-BFGS pour la minimisation de la perte.

## Installation :

```bash
pip install torch matplotlib scikit-learn pyDOE scipy
```

## Structure du projet

Voici les principaux fichiers du projet :

- **Chaleur_pinns.ipynb** [ici](https://github.com/GOHOUEDE/Difffusion-de-chaleur-avec-Pinns/blob/main/Chaleur_pinns.ipynb) : Le notebook qui pr√©sente le travail(code ,chargement et graphiques).
- **code.py** [ici](https://github.com/GOHOUEDE/Difffusion-de-chaleur-avec-Pinns/blob/main/Code.py) : Contient l'int√©gralit√© des codes python pour la simulation de la difussion de chaleur.
- **README.md** : Documentation du projet.

  
## Description du mod√®le

Le mod√®le utilise un r√©seau de neurones fully connected (FCN) pour approximer la solution de l'equation de difusion. Le r√©seau est entra√Æn√© √† l'aide de donn√©es de conditions aux limites et de points de collocation g√©n√©r√©s de mani√®re al√©atoire √† l'aide de l'√©chantillonnage hypercube latin.

Voici les √©tape:

1. **Conditions aux limites (BC)** : Le mod√®le est entra√Æn√© pour satisfaire les conditions aux limites d√©finies sur les bords du domaine.
2. **√âquation diff√©rentielle partielle (PDE)** : La perte est calcul√©e en fonction de la satisfaction de l'EDP √† l'int√©rieur du domaine en utilisant la d√©riv√©e de la solution par rapport aux variables spatiales et temporelles.

## Variables et Hyperparam√®tres

- **steps** : Le nombre d'it√©rations d'entra√Ænement.
- **lr** : Le taux d'apprentissage pour l'optimisation.
- **layers** : La structure du r√©seau de neurones (par exemple, [2, 32, 32, 1] pour un r√©seau avec 2 entr√©es, deux couches cach√©es de 32 neurones et une sortie).
- **Nu** : Le nombre de points d'entra√Ænement issus des conditions aux limites.
- **Nf** : Le nombre de points de collocation pour l'EDP.
- **x_min, x_max, t_min, t_max** : Les bornes spatiales et temporelles pour la simulation.
  
## Utilisation

1. **Pr√©paration des donn√©es** : On g√©nere des donn√©es d'entr√©e √† partir de points uniform√©ment espac√©s dans un domaine d√©fini.
2. **Entra√Ænement du mod√®le** : Le r√©seau de neurones est form√© sur les donn√©es de conditions aux limites et les points de collocation pour minimiser la fonction  perte.
3. **Visualisation** : Nous avons trac√© en 3D √† l'aide de Matplotlib les r√©sultats pour observer l'√©volution de la solution dans le domaine spatial et temporel.


## R√©sultats

Le r√©seau de neurones artificiels suppos√© comporte 4 couches cach√©es avec respectivement 2, 32, 32 et 1 neurones. Il est entra√Æn√© sur 20 000 √©tapes avec un taux d'apprentissage de \(1 \times 10^{-3}\). 

Pour g√©n√©rer de nouvelles donn√©es, nous d√©finissons une plage de valeurs pour \(x\) de 0 √† 1 et pour \(t\) de 0 √† 1, avec respectivement 200 et 100 points. Nous utilisons 100 points pour l‚Äôentra√Ænement (\(Nu\)) et 10 000 points pour l‚Äô√©valuation de l‚Äô√©quation aux d√©riv√©es partielles (\(Nf\)).

## Solution Analytique
Pour commencer, nous avons trac√© notre solution analytique, voici les figures obtenues :

- **Figures**: Solution analytique du mod√®le (image 1D et 2D)
  ![Description de l'image](plots/output_13_0.png)
-   ![Description de l'image](plots/output_13_1.png)


## 7.1 R√©seau Entra√Æn√© avec la Perte MSEu

On peut constater que le r√©seau a appris les \(Nu\) donn√©es exp√©rimentales et conditions initiales et respecte donc les conditions initiales et limites, mais n‚Äôa pas pu apprendre le ph√©nom√®ne (l‚ÄôEDP). De m√™me, une diff√©rence maximale de 0.09 est observ√©e. Les valeurs pr√©dites sont proches des r√©elles.

- **Figure 6**: Mod√®le entra√Æn√© avec la perte MSEu seule (Plan  1D et 2D)
 - ![Description de l'image](https://github.com/GOHOUEDE/Difffusion-de-chaleur-avec-Pinns/blob/main/plots/mseu1.png)
 - ![Description de l'image](https://github.com/GOHOUEDE/Difffusion-de-chaleur-avec-Pinns/blob/main/plots/MSEu2.png)

## 7.2 R√©seau Entra√Æn√© avec la Perte MSEf

Contrairement au cas pr√©c√©dent, on peut constater que le r√©seau a appris l‚ÄôEDP, mais cette fois-ci, il n'a pas appris les conditions initiales et limites. Une diff√©rence maximale de 0.09 est √©galement observ√©e. Les valeurs pr√©dites sont proches des r√©elles.
  ![Description de l'image](https://github.com/GOHOUEDE/Difffusion-de-chaleur-avec-Pinns/blob/main/plots/msef1.png)
- **Figure 8**: Mod√®le entra√Æn√© avec la perte MSEf seule (Plan 1D)
  ![Description de l'image](https://github.com/GOHOUEDE/Difffusion-de-chaleur-avec-Pinns/blob/main/plots/msef%202.png)
- **Figure 9**: Mod√®le entra√Æn√© avec la perte MSEf seule (Plan 2D)

## 7.3 R√©seau PINN

Maintenant, nous entra√Ænons notre r√©seau PINN avec une perte √©gale √† la somme des deux autres. Il est √©vident que le r√©seau apprend √† la fois l‚ÄôEDP et les conditions initiales et limites.
 ![Description de l'image](https://github.com/GOHOUEDE/Difffusion-de-chaleur-avec-Pinns/blob/main/plots/output_14_0.png)
- **Figure 10**: Solution analytique du mod√®le (image 1D)
 ![Description de l'image](https://github.com/GOHOUEDE/Difffusion-de-chaleur-avec-Pinns/blob/main/plots/output_14_1.png)
- **Figure 11**: Solution analytique du mod√®le (image 2D)

## Comparaison MSE

- On peut constater une simulation du ph√©nom√®ne proche du r√©el.
  -![Description de l'image](https://github.com/GOHOUEDE/Difffusion-de-chaleur-avec-Pinns/blob/main/plots/REEL.png)
- Ici la dir√©fence entre valeur r√©elles et valeurs pr√©dictes:
 -![Description de l'image](https://github.com/GOHOUEDE/Difffusion-de-chaleur-avec-Pinns/blob/main/plots/output_15_0.png)


